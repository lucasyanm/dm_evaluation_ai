{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lucasyanm/dm_evaluation_ai/blob/main/Fixed_Priority_Deadline_Monotonic_Schedule_Analysis_with_AI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eYm2X-aTxOGN"
      },
      "source": [
        "# Tagger\n",
        "The exact function to label a set of tasks as schedulable / not schedulable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vc1_vWjpxDK0"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "from typing import List\n",
        "\n",
        "def is_schedulable_rta(C: List[float], T: List[float], D: List[float]=None, max_iter=1000) -> bool:\n",
        "    \"\"\"\n",
        "    Exact RTA for fixed priority (assumes Deadline Monotonic: shorter period -> higher priority).\n",
        "    Returns True if the entire set is schedulable.\n",
        "    \"\"\"\n",
        "    n = len(C)\n",
        "    if D is None:\n",
        "        D = T.copy()\n",
        "\n",
        "    # order by ascending period (DM priority)\n",
        "    idx = sorted(range(n), key=lambda i: T[i])\n",
        "    C_ord = [C[i] for i in idx]\n",
        "    T_ord = [T[i] for i in idx]\n",
        "    D_ord = [D[i] for i in idx]\n",
        "\n",
        "    for k in range(n):\n",
        "        R_prev = C_ord[k]\n",
        "        converged = False\n",
        "        for _ in range(max_iter):\n",
        "            interference = 0.0\n",
        "            for i in range(k):  # only higher priority tasks\n",
        "                interference += math.ceil(R_prev / T_ord[i]) * C_ord[i]\n",
        "            R = C_ord[k] + interference\n",
        "            if R > D_ord[k]:\n",
        "                return False\n",
        "            if R == R_prev:\n",
        "                converged = True\n",
        "                break\n",
        "            R_prev = R\n",
        "        if not converged:\n",
        "            return False\n",
        "    return True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8rX_92cWzJUr"
      },
      "source": [
        "##Quick Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FWOnFi3hzH63",
        "outputId": "8f6db95e-e91d-4262-9fdc-6dbe70702725"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Schedulable? True\n"
          ]
        }
      ],
      "source": [
        "# quick example\n",
        "if __name__ == \"__main__\":\n",
        "    # execution time set\n",
        "    C = [1.0, 2.0, 1.5]\n",
        "    # period set\n",
        "    T = [10.0, 20.0, 30.0]\n",
        "    print(\"Schedulable?\", is_schedulable_rta(C, T))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bEsxF2-vzCln"
      },
      "source": [
        "# UUniFast and Dataset Generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xcXh1k81zFfK"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "def uunifast(total_u: float, n: int) -> list:\n",
        "    utilizations = []\n",
        "    sum_u = total_u\n",
        "    for i in range(1, n):\n",
        "        next_u = sum_u * (1.0 - random.random() ** (1.0/(n - i)))\n",
        "        utilizations.append(next_u)\n",
        "        sum_u -= next_u\n",
        "    utilizations.append(sum_u)\n",
        "    return utilizations\n",
        "\n",
        "# The total samples are n_samples * 10 to have the same quantity of groups for total utilization\n",
        "class TasksetDataset(Dataset):\n",
        "    def __init__(\n",
        "        self, n_samples: int,\n",
        "        min_tasks=3,\n",
        "        max_tasks=12,\n",
        "        period_range=(10, 1000),\n",
        "        deadline_factor_range=(0.2, 1.2),\n",
        "        seed=0):\n",
        "\n",
        "        random.seed(seed); np.random.seed(seed)\n",
        "        self.samples = []\n",
        "        for _ in range(n_samples):\n",
        "          # creating tasks\n",
        "          n = random.randint(min_tasks, max_tasks)\n",
        "\n",
        "          for total_u in np.round(np.arange(0.1, 1.1, 0.1),1):\n",
        "              # print(\"total u:\", total_u)\n",
        "              utilizationSet = uunifast(total_u, n)\n",
        "              periodSet = np.exp(np.random.uniform(np.log(period_range[0]), np.log(period_range[1]), size=n))\n",
        "              executionTimeSet = [max(1e-8, u * T) for u, T in zip(utilizationSet, periodSet)]\n",
        "\n",
        "              # Generate deadlines based on periodSet and deadline_factor_range\n",
        "              min_factor, max_factor = deadline_factor_range\n",
        "              deadlineSet = [T * random.uniform(min_factor, max_factor) for T in periodSet]\n",
        "\n",
        "              label = float(is_schedulable_rta(executionTimeSet, list(periodSet), list(deadlineSet)))\n",
        "              # Store C, T, D in tasks array\n",
        "              tasks = np.stack([np.array(executionTimeSet, dtype=np.float32),\n",
        "                                np.array(periodSet, dtype=np.float32),\n",
        "                                np.array(deadlineSet, dtype=np.float32)], axis=1)\n",
        "              self.samples.append((tasks, label))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    #it calls this method in any interation due to torch dataset inheritance\n",
        "    def __getitem__(self, idx):\n",
        "        return self.samples[idx]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4oHERydR8w-c"
      },
      "source": [
        "##Quick test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BsgGGy0e8uG4",
        "outputId": "444d2158-7745-4a24-f7bc-fb518db8fea9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(9, 3) 1.0\n",
            "(9, 3) 1.0\n",
            "(9, 3) 1.0\n",
            "(9, 3) 1.0\n",
            "(9, 3) 1.0\n",
            "(9, 3) 1.0\n",
            "(9, 3) 0.0\n",
            "(9, 3) 0.0\n",
            "(9, 3) 0.0\n",
            "(9, 3) 0.0\n",
            "(8, 3) 1.0\n",
            "(8, 3) 1.0\n",
            "(8, 3) 1.0\n",
            "(8, 3) 1.0\n",
            "(8, 3) 1.0\n",
            "(8, 3) 1.0\n",
            "(8, 3) 0.0\n",
            "(8, 3) 1.0\n",
            "(8, 3) 0.0\n",
            "(8, 3) 0.0\n",
            "(5, 3) 1.0\n",
            "(5, 3) 1.0\n",
            "(5, 3) 1.0\n",
            "(5, 3) 1.0\n",
            "(5, 3) 1.0\n",
            "(5, 3) 0.0\n",
            "(5, 3) 1.0\n",
            "(5, 3) 1.0\n",
            "(5, 3) 0.0\n",
            "(5, 3) 0.0\n",
            "(3, 3) 1.0\n",
            "(3, 3) 1.0\n",
            "(3, 3) 1.0\n",
            "(3, 3) 1.0\n",
            "(3, 3) 1.0\n",
            "(3, 3) 0.0\n",
            "(3, 3) 1.0\n",
            "(3, 3) 1.0\n",
            "(3, 3) 0.0\n",
            "(3, 3) 0.0\n",
            "(6, 3) 1.0\n",
            "(6, 3) 1.0\n",
            "(6, 3) 1.0\n",
            "(6, 3) 1.0\n",
            "(6, 3) 1.0\n",
            "(6, 3) 1.0\n",
            "(6, 3) 1.0\n",
            "(6, 3) 0.0\n",
            "(6, 3) 0.0\n",
            "(6, 3) 0.0\n"
          ]
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    ds = TasksetDataset(n_samples = 5)\n",
        "    for t, y in ds:\n",
        "        print(t.shape, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "walDOGBl-PS3"
      },
      "source": [
        "#Dataloader\n",
        "This `collate_fn` allows to use task sets of different sizes in the same batch. The mask is crucial for attention (to ignore padding positions)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S66I1yAK-QTQ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "def collate_tasksets(batch):\n",
        "    \"\"\"\n",
        "    batch: list of (tasks: np.array [n_i, 3], label: float) where 3 is (C, T, D)\n",
        "    Returns:\n",
        "      padded_tasks: tensor [B, Nmax, 3]\n",
        "      mask: bool tensor [B, Nmax] (True where it has data)\n",
        "      labels: tensor [B]\n",
        "    \"\"\"\n",
        "    tasks_list, labels = zip(*batch)\n",
        "    B = len(tasks_list)\n",
        "    lengths = [t.shape[0] for t in tasks_list]\n",
        "    Nmax = max(lengths)\n",
        "    # Now expects 3 features (C, T, D)\n",
        "    padded = np.zeros((B, Nmax, 3), dtype=np.float32)\n",
        "    mask = np.zeros((B, Nmax), dtype=np.bool_)\n",
        "    for i, t in enumerate(tasks_list):\n",
        "        L = t.shape[0]\n",
        "        padded[i, :L, :] = t\n",
        "        mask[i, :L] = True\n",
        "    return torch.from_numpy(padded), torch.from_numpy(mask), torch.tensor(labels, dtype=torch.float32)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sLKQ6bt9of_j"
      },
      "source": [
        "##Normalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TN9EIrcVohI9"
      },
      "outputs": [],
      "source": [
        "def collate_tasksets_normalized(batch):\n",
        "    padded, mask, labels = collate_tasksets(batch)\n",
        "\n",
        "    # Extract C, T, D from padded tasks (now shape [B, N, 3])\n",
        "    C = padded[..., 0]\n",
        "    periods = padded[..., 1]\n",
        "    deadlines = padded[..., 2]\n",
        "\n",
        "    # normalize periods using log\n",
        "    logT = torch.log1p(periods)\n",
        "\n",
        "    # scale C with T -> C_rel = C/T (avoid large variations)\n",
        "    C_rel = C / (periods + 1e-8)\n",
        "\n",
        "    # add relative deadline feature D_rel = D/T\n",
        "    D_rel = deadlines / (periods + 1e-8)\n",
        "\n",
        "    # concat features: [C, logT, C_rel, D_rel]\n",
        "    feats = torch.stack([C, logT, C_rel, D_rel], dim=-1)  # now shape [B, N, 4]\n",
        "\n",
        "    # compute aggregated features per set\n",
        "    n_tasks = mask.sum(dim=1, keepdim=True).float()  # [B,1]\n",
        "    total_util = (C_rel * mask.float()).sum(dim=1, keepdim=True)  # [B,1]\n",
        "    agg = torch.cat([n_tasks, total_util], dim=1)  # [B,2]\n",
        "    return feats, mask, labels, agg\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gGpcyKttCZfP"
      },
      "source": [
        "#Minimal Implementation of Set Transformer\n",
        "MAB, SAB and PMA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "otqbDWJwCe_v"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class MAB(nn.Module):\n",
        "    def __init__(self, dim_Q, dim_K, dim_V, num_heads, ln=True):\n",
        "        super().__init__()\n",
        "        self.fc_q = nn.Linear(dim_Q, dim_V)\n",
        "        self.fc_k = nn.Linear(dim_K, dim_V)\n",
        "        self.fc_v = nn.Linear(dim_K, dim_V)\n",
        "        self.attn = nn.MultiheadAttention(embed_dim=dim_V, num_heads=num_heads, batch_first=True)\n",
        "        self.fc_o = nn.Linear(dim_V, dim_V)\n",
        "        self.ln1 = nn.LayerNorm(dim_V) if ln else nn.Identity()\n",
        "        self.ln2 = nn.LayerNorm(dim_V) if ln else nn.Identity()\n",
        "        self.ff = nn.Sequential(nn.Linear(dim_V, dim_V), nn.ReLU(), nn.Linear(dim_V, dim_V))\n",
        "\n",
        "    def forward(self, Q, K, mask_K=None, return_attn=False):\n",
        "        q = self.fc_q(Q)\n",
        "        k = self.fc_k(K)\n",
        "        v = self.fc_v(K)\n",
        "        key_padding_mask = None\n",
        "\n",
        "        if mask_K is not None:\n",
        "            key_padding_mask = ~mask_K\n",
        "        attn_out, attn_weights = self.attn(q, k, v, key_padding_mask=key_padding_mask, need_weights=True)\n",
        "        out = self.ln1(Q + self.fc_o(attn_out))\n",
        "        out2 = self.ln2(out + self.ff(out))\n",
        "\n",
        "        if return_attn:\n",
        "            return out2, attn_weights  # attn_weights shape [B, qn, kn]\n",
        "        return out2\n",
        "\n",
        "class ISAB(nn.Module):\n",
        "    def __init__(self, dim, num_heads, num_inducing, ln=True):\n",
        "        super().__init__()\n",
        "        self.I = nn.Parameter(torch.randn(1, num_inducing, dim))\n",
        "        self.mab1 = MAB(dim_Q=self.I.shape[-1], dim_K=dim, dim_V=dim, num_heads=num_heads, ln=ln)\n",
        "        self.mab2 = MAB(dim_Q=dim, dim_K=self.I.shape[-1], dim_V=dim, num_heads=num_heads, ln=ln)\n",
        "    def forward(self, X, mask=None):\n",
        "        B = X.shape[0]\n",
        "        I_rep = self.I.expand(B, -1, -1)\n",
        "        H = self.mab1(I_rep, X, mask_K=mask)\n",
        "        return self.mab2(X, H)\n",
        "\n",
        "class PMA(nn.Module):\n",
        "    def __init__(self, dim, num_heads, num_seeds=1, ln=True):\n",
        "        super().__init__()\n",
        "        self.S = nn.Parameter(torch.randn(1, num_seeds, dim))\n",
        "        self.mab = MAB(dim_Q=self.S.shape[-1], dim_K=dim, dim_V=dim, num_heads=num_heads, ln=ln)\n",
        "    def forward(self, X, mask=None):\n",
        "        B = X.shape[0]\n",
        "        S_rep = self.S.expand(B, -1, -1)\n",
        "        return self.mab(S_rep, X, mask_K=mask)\n",
        "\n",
        "class SetTransformer(nn.Module):\n",
        "    def __init__(self, input_dim=4, dim=128, num_heads=4, num_inds=32, num_sab=2, pool_seeds=1, agg_dim=2):\n",
        "        super().__init__()\n",
        "        self.embed = nn.Sequential(nn.Linear(input_dim, dim), nn.ReLU(), nn.LayerNorm(dim))\n",
        "        self.encoder = nn.ModuleList([ISAB(dim=dim, num_heads=num_heads, num_inducing=num_inds) for _ in range(num_sab)])\n",
        "        self.pma = PMA(dim=dim, num_heads=num_heads, num_seeds=pool_seeds)\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(\n",
        "                dim * pool_seeds + agg_dim, dim//2),\n",
        "                nn.ReLU(),\n",
        "                nn.Dropout(0.1),\n",
        "                nn.Linear(dim//2, 1)\n",
        "          )\n",
        "\n",
        "    def forward(self, x, mask=None, agg=None):\n",
        "        h = self.embed(x)\n",
        "        for layer in self.encoder:\n",
        "            h = layer(h, mask=mask)\n",
        "        pooled = self.pma(h, mask=mask)\n",
        "        pooled = pooled.view(pooled.shape[0], -1)\n",
        "        if agg is not None:\n",
        "            pooled = torch.cat([pooled, agg.to(pooled.device)], dim=1)\n",
        "        logit = self.classifier(pooled).squeeze(1)\n",
        "        return logit\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lTOqR-gNCnsk"
      },
      "source": [
        "#Training and Inference Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RPIsKzFazTwa"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "\n",
        "def get_accuracy_rate(ys, preds):\n",
        "    \"\"\"\n",
        "    Calculate various accuracy metrics from true and predicted labels.\n",
        "    \"\"\"\n",
        "    # Calculate confusion matrix for the current bin\n",
        "    true_negative, false_positive, false_negative, true_positive = confusion_matrix(\n",
        "        ys, preds, labels=[0, 1]).ravel()\n",
        "\n",
        "    # True Positive Rate (Sensitivity/Recall)\n",
        "    true_positive_rate = true_positive / (true_positive + false_negative) if (true_positive + false_negative) > 0 else 0.0\n",
        "\n",
        "    # False Positive Rate (FPR)\n",
        "    false_positive_rate = false_positive / (true_negative + false_positive) if (true_negative + false_positive) > 0 else 0.0\n",
        "\n",
        "    # True Negative Rate (TNR)\n",
        "    true_negative_rate = true_negative / (true_negative + false_positive) if (true_negative + false_positive) > 0 else 0.0\n",
        "\n",
        "    # Overall Accuracy\n",
        "    accuracy = accuracy_score(ys, preds)\n",
        "\n",
        "    return true_positive_rate, false_positive_rate, true_negative_rate, accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eRUEHbsqCpA8"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score\n",
        "\n",
        "def train_epoch(model, loader, optim, device, pos_weight=None):\n",
        "    model.train()\n",
        "    losses = []\n",
        "    if pos_weight is None:\n",
        "        crit = nn.BCEWithLogitsLoss()\n",
        "    else:\n",
        "        crit = nn.BCEWithLogitsLoss(pos_weight=torch.tensor(pos_weight, device=device))\n",
        "    for feats, mask, labels, agg in loader:\n",
        "\n",
        "        feats = feats.to(device)\n",
        "        mask = mask.to(device)\n",
        "        labels = labels.to(device)\n",
        "        agg = agg.to(device)\n",
        "\n",
        "        optim.zero_grad()\n",
        "        logits = model(feats, mask=mask, agg=agg)\n",
        "        loss = crit(logits, labels)\n",
        "        loss.backward()\n",
        "        optim.step()\n",
        "        losses.append(loss.item())\n",
        "\n",
        "    return float(np.mean(losses))\n",
        "\n",
        "def evaluate(model, dataloader, device):\n",
        "    model.eval()\n",
        "    ys = []\n",
        "    preds = []\n",
        "    probs = []\n",
        "    all_aggs = [] # Initialize all_aggs here\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            # Corrected unpacking order: feats, mask, labels, agg\n",
        "            feats, mask, labels, agg = batch\n",
        "\n",
        "            feats = feats.to(device)\n",
        "            mask = mask.to(device)\n",
        "            labels = labels.to(device)\n",
        "            agg = agg.to(device)\n",
        "\n",
        "            logits = model(feats, mask=mask, agg=agg)\n",
        "            p = torch.sigmoid(logits)\n",
        "\n",
        "            pred = (p >= 0.5).long()\n",
        "            preds.extend(pred.cpu().numpy().tolist())\n",
        "            probs.extend(p.cpu().numpy().tolist())\n",
        "\n",
        "            ys.extend(labels.cpu().numpy().tolist())\n",
        "            all_aggs.extend(agg.cpu().numpy()) # Append agg to all_aggs\n",
        "\n",
        "    # compute metrics\n",
        "    # acc = accuracy_score(ys, preds)\n",
        "    prec = precision_score(ys, preds, zero_division=0)\n",
        "    rec = recall_score(ys, preds, zero_division=0)\n",
        "    f1 = f1_score(ys, preds, zero_division=0)\n",
        "    try:\n",
        "        auc = roc_auc_score(ys, probs)\n",
        "    except Exception:\n",
        "        auc = float(\"nan\")\n",
        "\n",
        "    # Calculate confusion matrix components\n",
        "    tpr, fpr, tnr, acc = get_accuracy_rate(ys, preds)\n",
        "\n",
        "    metrics_dict = {\n",
        "        \"accuracy\": acc,\n",
        "        \"precision\": prec,\n",
        "        \"recall\": rec,\n",
        "        \"f1\": f1,\n",
        "        \"auc\": auc,\n",
        "        \"tpr\": tpr,\n",
        "        \"fpr\": float(fpr),\n",
        "        \"tnr\": float(tnr)\n",
        "        }\n",
        "    return metrics_dict, ys, preds, all_aggs\n",
        "\n",
        "def compute_pos_weight(dataset):\n",
        "    # calculates pos_weight = N_neg / N_pos for BCEWithLogitsLoss\n",
        "    labels = [s[1] for s in dataset.samples]\n",
        "    neg = sum(1 for l in labels if l == 0.0)\n",
        "    pos = sum(1 for l in labels if l == 1.0)\n",
        "    if pos == 0:\n",
        "        return 1.0\n",
        "    return neg / pos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9R_Djhv6r5yi"
      },
      "source": [
        "#Main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c64cd320"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def plot_metrics_by_utilization(ys, preds, all_aggs, bins=np.arange(0.0, 1.01, 0.05)):\n",
        "    \"\"\"\n",
        "    Plots True Positive Rate, True Negative Rate, and False Positive Rate across utilization bins.\n",
        "\n",
        "    Args:\n",
        "        ys (list or np.array): True labels.\n",
        "        preds (list or np.array): Predicted labels.\n",
        "        all_aggs (list or np.array): Aggregated features, where the second column is total utilization.\n",
        "        bins (np.array): Array defining the edges of the utilization bins.\n",
        "    \"\"\"\n",
        "    ys = np.array(ys)\n",
        "    preds = np.array(preds)\n",
        "    all_aggs = np.array(all_aggs)\n",
        "\n",
        "    # Extract total utilization (second column of agg, index 1)\n",
        "    total_utilizations = all_aggs[:, 1]\n",
        "\n",
        "    tpr_per_bin = []\n",
        "    fpr_per_bin = []\n",
        "    tnr_per_bin = []\n",
        "    acc_per_bin = []\n",
        "    bin_centers = []\n",
        "\n",
        "    for i in range(len(bins) - 1):\n",
        "        lower_bound = bins[i]\n",
        "        upper_bound = bins[i+1]\n",
        "        bin_centers.append((lower_bound + upper_bound) / 2)\n",
        "\n",
        "        # Find samples within the current utilization bin\n",
        "        mask = (total_utilizations >= lower_bound) & (total_utilizations < upper_bound)\n",
        "        bin_ys = ys[mask]\n",
        "        bin_preds = preds[mask]\n",
        "\n",
        "        if len(bin_ys) > 0:\n",
        "          tpr, fpr, tnr, acc = get_accuracy_rate(bin_ys, bin_preds)\n",
        "\n",
        "          tpr_per_bin.append(tpr)\n",
        "          fpr_per_bin.append(fpr)\n",
        "          tnr_per_bin.append(tnr)\n",
        "          acc_per_bin.append(acc)\n",
        "        else:\n",
        "            # If no samples in bin, append NaN or 0 for metrics\n",
        "            tpr_per_bin.append(np.nan)\n",
        "            fpr_per_bin.append(np.nan)\n",
        "            tnr_per_bin.append(np.nan)\n",
        "            acc_per_bin.append(np.nan)\n",
        "\n",
        "    # Plotting\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.plot(\n",
        "        bin_centers,\n",
        "        acc_per_bin,\n",
        "        label='Overall Accuracy',\n",
        "        marker='^')\n",
        "    plt.plot(\n",
        "        bin_centers,\n",
        "        tpr_per_bin,\n",
        "        label='True Positive Rate (TPR)',\n",
        "        marker='o')\n",
        "    plt.plot(\n",
        "        bin_centers,\n",
        "        fpr_per_bin,\n",
        "        label='False Positive Rate (FPR)',\n",
        "        marker='s')\n",
        "    plt.plot(\n",
        "        bin_centers,\n",
        "        tnr_per_bin,\n",
        "        label='True Negative Rate (TNR)',\n",
        "        marker='x')\n",
        "\n",
        "    plt.xlabel('Total Utilization Bin')\n",
        "    plt.ylabel('Metric Value')\n",
        "    plt.title('Model Performance by Total Utilization (Test Set)')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.xticks(bins[::2]) # Show fewer x-ticks for better readability\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N6zvqvC4r7r2",
        "outputId": "3eeb1b04-7b59-4e13-dcc4-326f25666307"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pos_weight: 0.5155028362635581\n",
            "Epoch 01  TrainLoss: 0.1682  ValF1: 0.9224  ValAcc: 0.9031\n",
            "Epoch 02  TrainLoss: 0.1190  ValF1: 0.9445  ValAcc: 0.9284\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
        "import time # Import the time module\n",
        "\n",
        "def main():\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    seed = 123\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "\n",
        "    n_train, n_val, n_test = 100000, 80000, 100000\n",
        "    train_ds = TasksetDataset(n_train, seed=seed)\n",
        "    val_ds = TasksetDataset(n_val, seed=seed+1)\n",
        "    test_ds = TasksetDataset(n_test, seed=seed+2)\n",
        "\n",
        "    train_data_loader = DataLoader(\n",
        "        train_ds,\n",
        "        batch_size=128,\n",
        "        shuffle=True,\n",
        "        collate_fn=collate_tasksets_normalized\n",
        "      )\n",
        "    val_data_loader = DataLoader(\n",
        "        val_ds,\n",
        "        batch_size=128,\n",
        "        shuffle=False,\n",
        "        collate_fn=collate_tasksets_normalized\n",
        "      )\n",
        "    test_data_loader = DataLoader(\n",
        "        test_ds,\n",
        "        batch_size=128,\n",
        "        shuffle=False,\n",
        "        collate_fn=collate_tasksets_normalized\n",
        "      )\n",
        "\n",
        "    pos_weight = compute_pos_weight(train_ds)\n",
        "    print(\"pos_weight:\", pos_weight)\n",
        "\n",
        "    model = SetTransformer(\n",
        "        input_dim=4, # Changed from 3 to 4 to accommodate D_rel feature\n",
        "        dim=128,\n",
        "        num_heads=4,\n",
        "        num_inds=32,\n",
        "        num_sab=2,\n",
        "        pool_seeds=1,\n",
        "        agg_dim=2\n",
        "      )\n",
        "    model.to(device)\n",
        "\n",
        "    optim = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-5)\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "        optim,\n",
        "        mode='max',\n",
        "        factor=0.5,\n",
        "        patience=3\n",
        "      )\n",
        "    best_val_f1 = 0.0\n",
        "    best_path = \"best_set_transformer.pt\"\n",
        "\n",
        "    start_time = time.time() # Start timer\n",
        "\n",
        "    for epoch in range(1, 16):\n",
        "      train_loss = train_epoch(model, train_data_loader, optim, device, pos_weight=pos_weight)\n",
        "      val_metrics, _, _, _ = evaluate(model, val_data_loader, device)\n",
        "      scheduler.step(val_metrics[\"f1\"])\n",
        "\n",
        "      print(f\"Epoch {epoch:02d}  TrainLoss: {train_loss:.4f}  ValF1: {val_metrics['f1']:.4f}  ValAcc: {val_metrics['accuracy']:.4f}\")\n",
        "\n",
        "      if val_metrics[\"f1\"] > best_val_f1:\n",
        "          best_val_f1 = val_metrics[\"f1\"]\n",
        "          torch.save(model.state_dict(), best_path)\n",
        "\n",
        "    end_time = time.time() # End timer\n",
        "    total_time = end_time - start_time\n",
        "\n",
        "    # Convert total_time to hours, minutes, and seconds\n",
        "    hours = int(total_time // 3600)\n",
        "    minutes = int((total_time % 3600) // 60)\n",
        "    seconds = total_time % 60\n",
        "    print(f\"Total execution time: {hours}h {minutes}m {seconds:.2f}s\")\n",
        "\n",
        "    # evaluate on test set\n",
        "    start_time = time.time()\n",
        "    model.load_state_dict(torch.load(best_path, map_location=device))\n",
        "    end_time = time.time()\n",
        "\n",
        "    test_metrics, ys_test, preds_test, all_aggs_test = evaluate(model, test_data_loader, device)\n",
        "\n",
        "    print(\"Test metrics:\", test_metrics)\n",
        "    print(\"Test execution time:\", end_time - start_time)\n",
        "\n",
        "    # Call the plotting function\n",
        "    plot_metrics_by_utilization(ys_test, preds_test, all_aggs_test)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}